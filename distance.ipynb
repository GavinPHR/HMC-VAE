{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4531b47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904d6f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.distributions as D\n",
    "from tqdm import tqdm\n",
    "\n",
    "import image_dataset\n",
    "from hmc_vae import HMCVAE\n",
    "import utils\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61f41c9",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563b67e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_in, _ = image_dataset.get('FashionMNIST', 'data')\n",
    "hidden_channels = 32\n",
    "in_channels = train_dataset_in.tensors[0].shape[1]\n",
    "train_dataloader_in = DataLoader(train_dataset_in, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ce12be",
   "metadata": {},
   "source": [
    "### Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb193bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dataset = torchvision.datasets.FakeData(size=5000, image_size=(in_channels, 32, 32), transform=torchvision.transforms.ToTensor())\n",
    "noise_dataloader = DataLoader(noise_dataset, batch_size=100, shuffle=False)\n",
    "_, FashionMNIST_dataset = image_dataset.get('FashionMNIST', 'data', 5000)\n",
    "FashionMNIST_dataloader = DataLoader(FashionMNIST_dataset, batch_size=100, shuffle=False)\n",
    "_, MNIST_dataset = image_dataset.get('MNIST', 'data', 5000)\n",
    "MNIST_dataloader = DataLoader(MNIST_dataset, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf0486a",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31583e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HMCVAE(in_channels, latent_dim=100, hidden_channels=hidden_channels, T=10, L=5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13e0797",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_path = \"logs/FashionMNIST_17h_21m_17_Jul_2022_seed42/hmc_epoch10\"\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f2615c",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6d7620",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def plot(x1, x2=None):\n",
    "    if type(x1) is torch.Tensor:\n",
    "        x1 = x1.cpu().numpy()\n",
    "        x2 = x2.cpu().numpy()\n",
    "    plt.hist(x1, bins=50, alpha=0.4)\n",
    "    if x2 is not None:\n",
    "        plt.hist(x2, bins=50, alpha=0.4)\n",
    "    plt.show()\n",
    "\n",
    "def aucroc(score_in, score_out):\n",
    "    if type(score_in) is torch.Tensor:\n",
    "        score_in = score_in.cpu().numpy()\n",
    "        score_out = score_out.cpu().numpy()\n",
    "    ytrue = np.array([0]*len(score_in) + [1]*len(score_out))\n",
    "    yscore = np.concatenate([score_in, score_out])\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(ytrue, yscore)\n",
    "    plt.plot(fpr, tpr)\n",
    "    return metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6219782e",
   "metadata": {},
   "source": [
    "### Euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63ffeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L2(test_X, train_X):\n",
    "    mean_dist = []\n",
    "    for x in tqdm(test_X):\n",
    "        dist = torch.norm(train_X - x, dim=-1)\n",
    "        knn = dist.topk(20, dim=-1, largest=False)[0]\n",
    "        mean_dist.append(knn.mean())\n",
    "    return torch.tensor(mean_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e408f0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = L2(FashionMNIST_dataset.tensors[0].flatten(1)[:100], train_dataset_in.tensors[0].flatten(1)[:5000])\n",
    "d2 = L2(MNIST_dataset.tensors[0].flatten(1)[:100], train_dataset_in.tensors[0].flatten(1)[:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6330bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "aucroc(d1, d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24901ed4",
   "metadata": {},
   "source": [
    "### Cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404def8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(test_X, train_X):\n",
    "    mean_dist = []\n",
    "    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "    for x in tqdm(test_X):\n",
    "        dist = 1 - cos(train_X, x)\n",
    "        knn = dist.topk(20, dim=-1, largest=False)[0]\n",
    "        mean_dist.append(knn.mean())\n",
    "    return torch.tensor(mean_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c313ff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = cosine(FashionMNIST_dataset.tensors[0].flatten(1)[:100], train_dataset_in.tensors[0].flatten(1)[:5000])\n",
    "d2 = cosine(MNIST_dataset.tensors[0].flatten(1)[:100], train_dataset_in.tensors[0].flatten(1)[:5000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc351b9",
   "metadata": {},
   "source": [
    "### Mahalanobis\n",
    "\n",
    "Doesn't work on raw image inputs, some dimensions are constant and the covariance is not PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b350322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mahalanobis(test_X, train_X):\n",
    "    inv_cov = torch.inverse(torch.cov(train_X.t()))\n",
    "    mat = torch.cov(train_X.t())\n",
    "    assert bool((mat == mat.T).all() and (torch.eig(mat)[0][:,0]>=0).all())\n",
    "    mean = torch.mean(train_X, dim=0)\n",
    "    centered = test_X - mean\n",
    "    M = torch.mm(torch.mm(centered, inv_cov), centered.t())\n",
    "    print(torch.diag(M))\n",
    "    assert torch.all(torch.diag(M) >= 0)\n",
    "    return torch.sqrt(torch.diag(M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fe9ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = Mahalanobis(FashionMNIST_dataset.tensors[0].flatten(1)[:100], train_dataset_in.tensors[0].flatten(1)[:5000])\n",
    "d2 = Mahalanobis(MNIST_dataset.tensors[0].flatten(1)[:100], train_dataset_in.tensors[0].flatten(1)[:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0160ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
